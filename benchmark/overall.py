import csv
import json
import os
from collections import Counter
from typing import Tuple

from rdkit import Chem

from src.utils.pipeline_processing import *

log = logging.getLogger(__name__)


def extract_group_symbols(smiles_with_groups: str) -> Tuple[str, List[str]]:
    """
    ä»Žå¸¦åŸºå›¢ç¬¦å·çš„SMILESä¸­æå–åŸºå›¢ä¿¡æ¯

    Args:
        smiles_with_groups: å¸¦åŸºå›¢ç¬¦å·çš„SMILESå­—ç¬¦ä¸²

    Returns:
        tuple: (çº¯SMILESå­—ç¬¦ä¸², åŸºå›¢ç¬¦å·åˆ—è¡¨)
    """
    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é… |$...$| æ¨¡å¼
    pattern = r'\|\$([^$]*)\$\|'
    match = re.search(pattern, smiles_with_groups)

    if match:
        # æå–åŸºå›¢ç¬¦å·éƒ¨åˆ†
        group_part = match.group(1)
        # åˆ†å‰²åŸºå›¢ç¬¦å·ï¼ˆä»¥åˆ†å·åˆ†éš”ï¼‰
        group_symbols = [g.strip() for g in group_part.split(';') if g.strip()]

        # ç§»é™¤åŸºå›¢ç¬¦å·éƒ¨åˆ†ï¼Œå¾—åˆ°çº¯SMILES
        pure_smiles = re.sub(pattern, '', smiles_with_groups).strip()
        if len(group_symbols) == 1:
            group_symbols = []

        return pure_smiles, group_symbols
    else:
        # æ²¡æœ‰åŸºå›¢ç¬¦å·
        return smiles_with_groups.strip(), []


def process_smiles_list(smiles_list, isomeric=True):
    """
    æ ‡å‡†åŒ– SMILES åˆ—è¡¨ï¼šåŽ»é‡ã€åŽ»æ— æ•ˆã€è½¬ä¸º Cano-SMILES
    """
    canonical_set = set()
    valid_smiles = []

    for s in smiles_list:
        try:
            mol = Chem.MolFromSmiles(s.strip())
            if mol is not None:
                # ç”Ÿæˆè§„èŒƒ SMILESï¼ˆä¿ç•™ç«‹ä½“åŒ–å­¦ï¼‰
                cano_smi = Chem.MolToSmiles(mol, isomericSmiles=isomeric)

                pure_smi, group_symbols = extract_group_symbols(s)
                tail = ''.join(sorted(group_symbols))

                if cano_smi not in canonical_set:
                    canonical_set.add(cano_smi)
                    valid_smiles.append(cano_smi + tail)
        except:
            continue  # è·³è¿‡æ— æ•ˆ

    return valid_smiles   # è¿”å›žæ— é‡å¤ã€æœ‰æ•ˆçš„è§„èŒƒ SMILES åˆ—è¡¨


def evaluate_smiles(pred_smiles, true_smiles):
    """
    è¯„ä¼°å•å¼ å›¾åƒçš„è¯†åˆ«ç»“æžœ
    """
    # å¤„ç† SMILES åˆ—è¡¨ï¼ˆå¦‚åŽ»ç©ºæ ¼ã€æ ‡å‡†åŒ–ç­‰ï¼‰
    pred_list = process_smiles_list(pred_smiles)
    true_list = process_smiles_list(true_smiles)

    # ä½¿ç”¨ Counter ç»Ÿè®¡é¢‘æ¬¡
    pred_counter = Counter(pred_list)
    true_counter = Counter(true_list)

    # è®¡ç®— TP: æ¯ä¸ª item çš„æœ€å°é¢‘æ¬¡ä¹‹å’Œï¼ˆäº¤é›†ï¼‰
    tp = sum(min(pred_counter[k], true_counter[k]) for k in (pred_counter & true_counter))

    # è®¡ç®— FP: é¢„æµ‹å¤šå‡ºçš„éƒ¨åˆ†
    fp = sum(max(0, pred_counter[k] - true_counter.get(k, 0)) for k in pred_counter)

    # è®¡ç®— FN: çœŸå®žæ¼æŽ‰çš„éƒ¨åˆ†
    fn = sum(max(0, true_counter[k] - pred_counter.get(k, 0)) for k in true_counter)

    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0
    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0
    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0

    return {
        'precision': precision,
        'recall': recall,
        'f1': f1,
        'tp': tp, 'fp': fp, 'fn': fn,
        'num': len(pred_smiles)
    }


def load_results(label_dir: str, image_dir: str):
    names = [name[:-4] for name in os.listdir(image_dir) if name.endswith('png')]

    results = []
    for name in names:
        json_path = os.path.join(label_dir, f"{name}.json")
        try:
            with open(json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            cmpds = data.get("compounds", {}).get('cmpds', [])
            if not cmpds:
                print(f"æœªæ­£ç¡®å®Œæˆï¼š{name}")
        except Exception:
            results.append([])
            continue
        smiles_list = [cmpd['smiles'] for cmpd in cmpds]
        results.append({'name': name, 'smiles_list': smiles_list})
    return results


def total_eval():
    total_tp = 0
    total_fp = 0
    total_fn = 0

    all_predictions = load_results(pred_path, image_path)
    all_ground_truths = load_results(gold_path, image_path)

    # ç”¨äºŽä¿å­˜æ¯è½®ç»“æžœ
    per_image_results = []

    for idx, (img_pred, img_true) in enumerate(zip(all_predictions, all_ground_truths)):
        result = evaluate_smiles(img_pred['smiles_list'], img_true['smiles_list'])
        tp, fp, fn = result['tp'], result['fp'], result['fn']

        # ç´¯åŠ 
        total_tp += tp
        total_fp += fp
        total_fn += fn

        # ä¿å­˜æœ¬è½®ç»“æžœï¼ˆå‡è®¾ img_pred / img_true æ˜¯ dict ä¸”åŒ…å« 'å›¾åƒå' å­—æ®µï¼‰
        image_name = img_pred['name']
        per_image_results.append({
            'å›¾åƒå': image_name,
            'TP': tp,
            'FP': fp,
            'FN': fn,
            'Precision': tp / (tp + fp) if (tp + fp) > 0 else 0.0,
            'Recall': tp / (tp + fn) if (tp + fn) > 0 else 0.0,
        })

    # ä¿å­˜æœ¬è½®æ‰€æœ‰å›¾åƒçš„è¯¦ç»†ç»“æžœåˆ° CSVï¼ˆä½¿ç”¨å…¨å±€ i å‘½åï¼‰
    output_file = f"eval_result_{i}.csv"
    with open(output_file, 'w', encoding='utf-8-sig', newline='') as f:
        fieldnames = ['å›¾åƒå', 'TP', 'FP', 'FN', 'Precision', 'Recall']
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(per_image_results)

    # print(f"ðŸ“Š è¯„ä¼°ç»“æžœå·²ä¿å­˜åˆ°: {output_file}")

    # è®¡ç®—å…¨å±€æŒ‡æ ‡
    global_precision = total_tp / (total_tp + total_fp) if (total_tp + total_fp) > 0 else 0.0
    global_recall = total_tp / (total_tp + total_fn) if (total_tp + total_fn) > 0 else 0.0
    global_f1 = 2 * global_precision * global_recall / (global_precision + global_recall) if (
                                                                                                     global_precision + global_recall) > 0 else 0.0

    return global_precision, global_recall, global_f1


if __name__ == '__main__':
    gold_path = "../evaluate_dataset/gold"
    image_path = "../evaluate_dataset/images"
    print('epcho     Precision     Recall    F1\n')
    for i in range(6):
        pred_path = os.path.join("../result", f'{i}')
        precision, recall, f1 = total_eval()
        print(f'{i}         {precision:.3f}      {recall:.3f}       {f1:.3f}\n')